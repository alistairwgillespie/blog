---
keywords: fastai
description: "A high-level breakdown of a neural network."
title: "Architecture of a Neural Network"
toc: false
branch: master
badges: false
tags: true
image: images/copied_from_nb/architecture_imgs/architecture.png
comments: true
categories: [deeplearning]
author: Alistair Gillespie
nb_path: _notebooks/2021-12-02-Neural-Network-Architecture.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-02-Neural-Network-Architecture.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's time to progress on to the architecture of a neural network. By way of doing this we will address some deep learning jargon. At a high level there are three main components to a generic neural network: the input layer made up of input neurons, the output layer made up of output neurons, and the hidden layer. The hidden layer is literally any layer that is not an input or output layer. It's funny, for a while I wasn't sure what a hidden layer meant. Does a hidden layer get it's name due to some mathematical significance? The answer is no. Like I said before, it's just a layer that is neither an input or output layer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/images/copied_from_nb/architecture_imgs/architecture.png" alt="Architecture of Neural Network"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's go ahead and introduce another hidden layer to our architecture. Now that we have an additional layer some folks might refer to this architecture as a multilayer perceptron. The reason this name is used is largerly due to the history of neural networks. This terminology is used despite the fact that most architectures use sigmoid neurons instead of perceptrons - it's misleading to say the least. An example of this can be found in this <a href="https://www.microsoft.com/security/blog/2021/07/27/combing-through-the-fuzz-using-fuzzy-hashing-and-deep-learning-to-counter-malware-detection-evasion-techniques/" title="Combing through the fuzz">article</a> by Microsoft on applying multilayer perceptrons to polymorphic malware classification. I find it hard to believe that the temperamental perceptron is doing the heavylifting in this case, but I could be wrong.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/images/copied_from_nb/architecture_imgs/mlp.png" alt="Architecture of Neural Network"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The number of layers and neurons is defined based on the task. For example, if we want to classify a 256 x 256 grayscale images of cats, we would define an input later of 65,536 input neurons (256 x 256). Each neuron then represents the intensity of each corresponding pixel from the image - scaled between 0 and 1. The output layer, containing a single output neuron, would produce a value between 0 and 1, with values above 0.5 indicating the image contains a cat, and values less than 0.5 indicating the image doesn't contain a cat.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another important property of this network is that each layer of neurons provides inputs to the next layer in the network. This property is called feedforward; in other words, there are no loops in the network. So there we have it, a quick introduction to feedforward neural networks.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This post was developed with the help of:</p>
<iframe src="https://open.spotify.com/embed/track/3ZdVayrMwJEzi99uOss8he?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
</div>
</div>
</div>
</div>
 

