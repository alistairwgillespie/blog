<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Sigmoid Neurons | Alistair Gillespie</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Sigmoid Neurons" />
<meta name="author" content="Alistair Gillespie" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Getting neural with Sigmoids." />
<meta property="og:description" content="Getting neural with Sigmoids." />
<link rel="canonical" href="http://alistairgillespie.io/deeplearning/2021/11/25/Sigmoid-Neurons.html" />
<meta property="og:url" content="http://alistairgillespie.io/deeplearning/2021/11/25/Sigmoid-Neurons.html" />
<meta property="og:site_name" content="Alistair Gillespie" />
<meta property="og:image" content="http://alistairgillespie.io/images/copied_from_nb/sigmoid_imgs/sigmoid.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-25T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"http://alistairgillespie.io/deeplearning/2021/11/25/Sigmoid-Neurons.html","@type":"BlogPosting","headline":"Sigmoid Neurons","dateModified":"2021-11-25T00:00:00-06:00","datePublished":"2021-11-25T00:00:00-06:00","image":"http://alistairgillespie.io/images/copied_from_nb/sigmoid_imgs/sigmoid.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://alistairgillespie.io/deeplearning/2021/11/25/Sigmoid-Neurons.html"},"author":{"@type":"Person","name":"Alistair Gillespie"},"description":"Getting neural with Sigmoids.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://alistairgillespie.io/feed.xml" title="Alistair Gillespie" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Alistair Gillespie</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Sigmoid Neurons</h1><p class="page-description">Getting neural with Sigmoids.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-25T00:00:00-06:00" itemprop="datePublished">
        Nov 25, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Alistair Gillespie</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#deeplearning">deeplearning</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-11-25-Sigmoid-Neurons.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Perceptrons got a lot of folks excited back in the day. However, there are was a bit of a problem. Say we are trying to classify digits correctly using a network of perceptrons. Our model takes an input image of the digit "1", and incorrectly classifies it as a "2". Why don't we just go ahead and tweak the weights and bias to improve our model's classification? Well, we can, but by doing so we get unpredictable results. For example, say we do tune the parameters and correctly predict "1" in the next training run, but now our model is performing poorly on other digits. We've essentially kicked the can down the road, and our model begins to juggle between different weights and biases with no significant gains in accuracy across all digits. A big reason for this is that perceptrons are sensitive to changes in their parameters, even the slightest changes to the parameters produce a different output. Instead, we need a model that gives us greater control of the output so we are able to fine tune the model to achieve better performance. In other words, for any small change in the weights and bias, we only want a small change in the output.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With this simple idea, the sigmoid neuron was born. The math can be kinda scary at first but some generous folks have broken it down into edible chunks for us <sup id="fnref-1" class="footnote-ref"><a href="#fn-1">1</a></sup>. I'll summarise for you. The sigmoid has similar qualities to a perceptron but a few key differences. Like it's sibling, the sigmoid neuron still takes inputs $x_1, x_2, ..., x_j$, however $x_j$ can be any value between $0$ and $1$ (e.g. 0.7456). Weights are still assigned to each input $w_1, w_2, ..., w_3$, and the overall bias remains. However, the output is no longer a 0 or 1, instead it's any number between 0 and 1 depending on the magnitude of $w.x + b$. This is because of the $\sigma$ being applied to get $\sigma(w.x +b)$. So what does the sigmoid part of it actually do? It does this:
$$\sigma(z) \equiv \frac{1}{1+e^{-z}}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before we simplify things, let's go another step further to make things more explicit. The output of a sigmoid neuron with the inputs, weights and bias detailed above is:
$$ \frac{1}{1 + \exp(-\sum_jw_jx_j-b)}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wowza. It's starting to look pretty funky. Despite our function looking more complex, the sigmoid neuron still possesses similarities to the perceptron. For instance, say $z$, or $w.x+b$ is a big number - $x^{-z}=2.718281828^{-100}=0$. Finishing the calculation, and the output is 1. So when $w.x + b$ is large and positive, the output will be approximately 1. On the other hand, if the input is large and negative, the output will be approximately 0. This is awfully similar to the perceptron, right?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This post was developed with the help of:</p>
<iframe src="https://open.spotify.com/embed/track/7pLoI3XJLM67CGKAnOf5M5?utm_source=generator" width="100%" height="380" frameborder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="footnotes"><p id="fn-1">1. <a href="#fnref-1" class="footnote footnotes">↩</a></p></div></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="alistairwgillespie/"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/deeplearning/2021/11/25/Sigmoid-Neurons.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A blog about machine learning, AI, cybersecurity and sports.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/alistairwgillespie" title="alistairwgillespie"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/dizzy_data" title="dizzy_data"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
